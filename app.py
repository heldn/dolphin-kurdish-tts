import sys
import os

# 1. SETUP DIRECTORIES (Must happen before AI imports)
if getattr(sys, 'frozen', False):
    BASE_DIR = os.path.dirname(sys.executable)
else:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

MODEL_CACHE_DIR = os.path.join(BASE_DIR, "models_cache")
os.makedirs(MODEL_CACHE_DIR, exist_ok=True)

# Redirect all AI models to a local cache folder for portability
os.environ["HF_HOME"] = MODEL_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = MODEL_CACHE_DIR
os.environ["PYTHONHASHSEED"] = "0"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# Force offline mode if models are already present
if os.path.exists(os.path.join(MODEL_CACHE_DIR, "models--razhan--mms-tts-ckb")):
    os.environ["HF_HUB_OFFLINE"] = "1"
    print("Status: Offline Mode Active (Using local models)")
else:
    print("Status: Online Mode (Will download models on first run)")

import re
import json
import zipfile
from datetime import datetime
import logging

# Handle console output
print("====================================")
print("   ğŸ¬ Dolphin KURDISH TTS ğŸ¬")
print("====================================")
print("Status: Initializing AI Engine...")
print(f"Model cache directory: {os.environ['HF_HOME']}")
print("Note: First launch takes longer to unpack libraries.")
print("------------------------------------")

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

import gradio as gr
from transformers import VitsModel, AutoTokenizer
import torch
import numpy as np
import librosa
import soundfile as sf
from pydub import AudioSegment

# --- CONFIGURATION ---
OUTPUT_FOLDER_NAME = "audio_output"
OUTPUT_FOLDER = os.path.join(BASE_DIR, OUTPUT_FOLDER_NAME)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

MODELS = {
    "Sorani": "razhan/mms-tts-ckb",
    "Sorani (Alternative)": "akam-ot/ckb-tts",
    "Kurmanji (Arabic Script)": "facebook/mms-tts-kmr-script_arabic",
    "Kurmanji (Latin Script)": "facebook/mms-tts-kmr-script_latin",
    "Arabic (Standard - MMS)": "facebook/mms-tts-ara",
    "Arabic (Habibi - Dialectal)": "SWivid/Habibi-TTS",
    "Multi-Language (Kokoro-82M)": "hexgrad/Kokoro-82M"
}

HABIBI_DIALECTS = ["MSA", "SAU", "UAE", "ALG", "IRQ", "EGY", "MAR", "OMN", "TUN", "LEV", "SDN", "LBY"]

KOKORO_LANGS = {
    "American English": "a",
    "British English": "b",
    "Spanish": "e",
    "French": "f",
    "Hindi": "h",
    "Italian": "i",
    "Brazilian Portuguese": "p",
    "Japanese": "j",
    "Mandarin Chinese": "z"
}

KOKORO_VOICES = {
    "a": ["af_bella", "af_nicole", "af_sarah", "af_sky", "am_adam", "am_michael"],
    "b": ["bf_emma", "bf_isabella", "bm_george", "bm_lewis"],
    "e": ["ef_dora", "em_alex", "em_santa"],
    "f": ["ff_siwis"],
    "h": ["hf_alpha", "hf_beta", "hm_omega", "hm_psi"],
    "i": ["if_sara", "im_nicola"],
    "p": ["pf_dora", "pm_alex", "pm_santa"],
    "j": ["jf_alpha", "jf_gongitsune", "jf_nezumi", "jf_tebukuro", "jm_kuma"],
    "z": ["zf_xiaobei", "zf_xiaoni", "zf_xiaoxiao", "zf_xiaoyu", "zm_yunjian", "zm_yunxi", "zm_yunxia", "zm_yunyang"]
}

# --- TRANSLATIONS ---
TRANSLATIONS = {
    "English": {
        "title": "ğŸ¬ Dolphin KURDISH TTS",
        "author": "By Heldn Hastyar Abdullah",
        "studio_tab": "ğŸ›ï¸ Studio",
        "cleaner_tab": "ğŸ§¹ Text Cleaner",
        "about_tab": "â„¹ï¸ About",
        "dialect": "Dialect",
        "upload_txt": "ğŸ“„ Upload .txt file",
        "unlimited_text": "âœ… Supports unlimited text length!",
        "input_placeholder": "Enter Kurdish text here...",
        "input_label": "Input Kurdish Text",
        "pauses_accordion": "â¸ï¸ Natural Pauses",
        "comma_pause": "Comma pause (seconds)",
        "sentence_pause": "Sentence pause (seconds)",
        "audio_settings": "âš™ï¸ Audio Settings",
        "speed": "Speed",
        "pitch": "Pitch",
        "export_mp3": "Export as MP3 (Smaller File)",
        "generate_btn": "ğŸ”Š Generate Speech",
        "audio_preview": "Audio Preview",
        "audio_file": "Audio File",
        "subtitles": "Subtitles (.srt)",
        "zip_bundle": "ğŸ“¦ ZIP Bundle",
        "clean_title": "### Fix broken Kurdish characters",
        "clean_desc": "Paste messy text to normalize Kurdish letters and numbers.",
        "original_text": "Original Text",
        "clean_btn": "Clean Text",
        "cleaned_text": "Cleaned Text",
        "usage_tips": "### Usage Tips",
        "tip_q": "- **Max quality**: Use proper Kurdish punctuation",
        "tip_l": "- **Long texts**: Upload .txt files for best results",
        "tip_s": "- **Sorani users**: Automatic character fixing enabled",
        "tip_v": "- **Video creators**: Download ZIP bundle (audio + subtitles)",
        "footer": "<strong>ğŸ¬ Dolphin KURDISH TTS</strong> â€¢ Created by <em>Heldn Hastyar Abdullah</em> â€¢ Free & Open Source",
        "error_empty": "âŒ Please enter some text!",
        "error_clean_empty": "âŒ Text became empty after cleaning!",
        "error_process": "âŒ Could not process text!",
        "habibi_dialects_label": "Arabic Dialects (Habibi)",
        "habibi_clone_label": "ğŸ™ï¸ Voice Cloning (Optional)",
        "habibi_ref_wav_label": "Reference Audio",
        "habibi_ref_txt_label": "Reference Text",
        "habibi_ref_txt_placeholder": "What is said in the audio?",
        "kokoro_lang_label": "Language",
        "kokoro_voice_label": "Voice"
    },
    "Kurdish": {
        "title": "ğŸ¬ Ø¯Û†ÚµÙÛŒÙ† Ø¨Û† Ú¯Û†Ú•ÛŒÙ†ÛŒ Ø¯Û•Ù‚ Ø¨Û† Ø¯Û•Ù†Ú¯",
        "author": "Ù„Û•Ù„Ø§ÛŒÛ•Ù† Ù‡ÛÚµØ¯Ù† Ù‡Û•Ø³ØªÛŒØ§Ø± Ø¹Û•Ø¨Ø¯ÙˆÚµØ§",
        "studio_tab": "ğŸ›ï¸ Ø³ØªÛ†Ø¯ÛŒÛ†",
        "cleaner_tab": "ğŸ§¹ Ú†Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Û•Ù‚",
        "about_tab": "â„¹ï¸ Ø¯Û•Ø±Ø¨Ø§Ø±Û•",
        "dialect": "Ø´ÛÙˆÛ•Ø²Ø§Ø±",
        "upload_txt": "ğŸ“„ Ø¨Ø§Ø±Ú©Ø±Ø¯Ù†ÛŒ ÙØ§ÛŒÙ„ÛŒ .txt",
        "unlimited_text": "âœ… Ø¯Û•ØªÙˆØ§Ù†ÛŒ Ø¯Û•Ù‚ÛŒ Ø¨ÛØ³Ù†ÙˆÙˆØ± Ø¨Ù†ÙˆØ³ÛŒ!",
        "input_label": "Ø¯Û•Ù‚ÛŒ Ú©ÙˆØ±Ø¯ÛŒ Ø¯Ø§Ø®Úµ Ø¨Ú©Û•",
        "input_placeholder": "Ø¯Û•Ù‚ÛŒ Ú©ÙˆØ±Ø¯ÛŒ Ù„ÛØ±Û• Ø¨Ù†ÙˆØ³Û•...",
        "pauses_accordion": "â¸ï¸ ÙˆÛ•Ø³ØªØ§Ù†Û• Ø³Ø±ÙˆØ´ØªÛŒÛŒÛ•Ú©Ø§Ù†",
        "comma_pause": "ÙˆÛ•Ø³ØªØ§Ù†ÛŒ ÙØ§Ø±ÛŒØ²Û• (Ú†Ø±Ú©Û•)",
        "sentence_pause": "ÙˆÛ•Ø³ØªØ§Ù†ÛŒ Ø®Ø§Úµ (Ú†Ø±Ú©Û•)",
        "audio_settings": "âš™ï¸ Ú•ÛÚ©Ø®Ø³ØªÙ†ÛŒ Ø¯Û•Ù†Ú¯",
        "speed": "Ø®ÛØ±Ø§ÛŒÛŒ",
        "pitch": "ØªÛ†Ù†ÛŒ Ø¯Û•Ù†Ú¯",
        "export_mp3": "Ù‡Û•Ù†Ø§Ø±Ø¯Û•Ú©Ø±Ø¯Ù† Ø¨Û• MP3",
        "generate_btn": "ğŸ”Š Ø¯Ø±ÙˆØ³ØªÚ©Ø±Ø¯Ù†ÛŒ Ø¯Û•Ù†Ú¯",
        "audio_preview": "Ú¯ÙˆÛÚ¯Ø±ØªÙ†",
        "audio_file": "ÙØ§ÛŒÙ„ÛŒ Ø¯Û•Ù†Ú¯",
        "subtitles": "Ú˜ÛØ±Ù†ÙˆÙˆØ³ (.srt)",
        "zip_bundle": "ğŸ“¦ ÙØ§ÛŒÙ„ÛŒ ZIP",
        "clean_title": "### Ú†Ø§Ú©Ú©Ø±Ø¯Ù†ÛŒ Ù¾ÛŒØªÛ• ØªÛÚ©Ú†ÙˆÙˆÛ•Ú©Ø§Ù†",
        "clean_desc": "Ø¯Û•Ù‚ÛŒ ØªÛÚ©Ú†ÙˆÙˆ Ù„ÛØ±Û• Ø¯Ø§Ø¨Ù†Û Ø¨Û† Ø¦Û•ÙˆÛ•ÛŒ Ù¾ÛŒØª Ùˆ Ú˜Ù…Ø§Ø±Û•Ú©Ø§Ù†ÛŒ Ú•ÛÚ©Ø¨Ø®Û•ÛŒØªÛ•ÙˆÛ•.",
        "original_text": "Ø¯Û•Ù‚ÛŒ Ø³Û•Ø±Û•Ú©ÛŒ",
        "clean_btn": "Ú•ÛÚ©Ø®Ø³ØªÙ†ÛŒ Ø¯Û•Ù‚",
        "cleaned_text": "Ø¯Û•Ù‚ÛŒ Ú•ÛÚ©Ø®Ø±Ø§Ùˆ",
        "usage_tips": "### Ø¦Ø§Ù…Û†Ú˜Ú¯Ø§Ø±ÛŒÛŒÛ•Ú©Ø§Ù†",
        "tip_q": "- **Ø¨Ø§Ø´ØªØ±ÛŒÙ† Ú©ÙˆØ§Ù„ÛØªÛŒ**: Ù†ÛŒØ´Ø§Ù†Û•Ú©Ø§Ù†ÛŒ (ØŒ . ØŸ !) Ø¨Û•Ú©Ø§Ø±Ø¨Ù‡ÛÙ†Û•",
        "tip_l": "- **Ø¯Û•Ù‚ÛŒ Ø¯Ø±ÛÚ˜**: ÙØ§ÛŒÙ„ÛŒ .txt Ø¨Û•Ú©Ø§Ø±Ø¨Ù‡ÛÙ†Û•",
        "tip_s": "- **Ø¨Û† Ø³Û†Ø±Ø§Ù†ÛŒ**: Ú†Ø§Ú©Ø³Ø§Ø²ÛŒ Ù¾ÛŒØªÛ•Ú©Ø§Ù† Ú†Ø§Ù„Ø§Ú©Ú©Ø±Ø§ÙˆÛ•",
        "tip_v": "- **Ø¨Û† Ú¤ÛŒØ¯ÛŒÛ†**: ÙØ§ÛŒÙ„ÛŒ ZIP Ø¯Ø§Ø¨Û•Ø²ÛÙ†Û•",
        "footer": "<strong>Ø¯Û†ÚµÙÛŒÙ† Ø¨Û† Ú¯Û†Ú•ÛŒÙ†ÛŒ Ø¯Û•Ù‚ Ø¨Û† Ø¯Û•Ù†Ú¯</strong> â€¢ Ù„Û•Ù„Ø§ÛŒÛ•Ù† <em>Ù‡ÛÚµØ¯Ù† Ù‡Û•Ø³ØªÛŒØ§Ø± Ø¹Û•Ø¨Ø¯ÙˆÚµØ§</em>",
        "error_empty": "âŒ ØªÚ©Ø§ÛŒÛ• Ø¯Û•Ù‚ÛÚ© Ø¨Ù†ÙˆØ³Û•!",
        "error_clean_empty": "âŒ Ø¯Û•Ù‚Û•Ú©Û• Ø®Ø§ÚµÛŒÛŒÛ•!",
        "error_process": "âŒ Ú©ÛØ´Û•ÛŒÛ•Ú© Ú•ÙˆÙˆÛŒØ¯Ø§!",
        "habibi_dialects_label": "Ø´ÛÙˆÛ•Ø²Ø§Ø±Û• Ø¹Û•Ø±Û•Ø¨ÛŒÛŒÛ•Ú©Ø§Ù† (Ø­Û•Ø¨ÛŒØ¨ÛŒ)",
        "habibi_clone_label": "ğŸ™ï¸ Ú©Û†Ù¾ÛŒÚ©Ø±Ø¯Ù†ÛŒ Ø¯Û•Ù†Ú¯ (Ø¦Ø§Ø±Û•Ø²ÙˆÙˆÙ…Û•Ù†Ø¯Ø§Ù†Û•)",
        "habibi_ref_wav_label": "Ø¯Û•Ù†Ú¯ÛŒ Ø¨Ù†Ú†ÛŒÙ†Û•",
        "habibi_ref_txt_label": "Ø¯Û•Ù‚ÛŒ Ø¨Ù†Ú†ÛŒÙ†Û•",
        "habibi_ref_txt_placeholder": "Ú†ÛŒ ÙˆØªØ±Ø§ÙˆÛ• Ù„Û• Ø¯Û•Ù†Ú¯Û•Ú©Û•Ø¯Ø§ØŸ",
        "kokoro_lang_label": "Ø²Ù…Ø§Ù†",
        "kokoro_voice_label": "Ø¯Û•Ù†Ú¯"
    },
    "Arabic": {
        "title": "ğŸ¬ Ø¯ÙˆÙ„ÙÙŠÙ† Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…",
        "author": "Ø¨ÙˆØ§Ø³Ø·Ø© Ù‡ÙŠÙ„Ø¯Ù† Ù‡ÙŠØ³ØªÙŠØ§Ø± Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡",
        "studio_tab": "ğŸ›ï¸ Ø³ØªÙˆØ¯ÙŠÙˆ",
        "cleaner_tab": "ğŸ§¹ Ù…Ù†Ø¸Ù Ø§Ù„Ù†Øµ",
        "about_tab": "â„¹ï¸ Ø­ÙˆÙ„",
        "dialect": "Ø§Ù„Ù„Ù‡Ø¬Ø©",
        "upload_txt": "ğŸ“„ Ø±ÙØ¹ Ù…Ù„Ù .txt",
        "unlimited_text": "âœ… ÙŠØ¯Ø¹Ù… Ù†ØµÙˆØµØ§Ù‹ ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯Ø© Ø§Ù„Ø·ÙˆÙ„!",
        "input_label": "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ±Ø¯ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "input_placeholder": "Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§...",
        "pauses_accordion": "â¸ï¸ ÙÙˆØ§ØµÙ„ Ø·Ø¨ÙŠØ¹ÙŠØ©",
        "comma_pause": "ÙØ§ØµÙ„ Ø§Ù„ÙØ§ØµÙ„Ø© (Ø«ÙˆØ§Ù†ÙŠ)",
        "sentence_pause": "ÙØ§ØµÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© (Ø«ÙˆØ§Ù†ÙŠ)",
        "audio_settings": "âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª",
        "speed": "Ø§Ù„Ø³Ø±Ø¹Ø©",
        "pitch": "Ø§Ù„Ù†ØºÙ…Ø©",
        "export_mp3": "ØªØµØ¯ÙŠØ± Ø¨ØµÙŠØºØ© MP3",
        "generate_btn": "ğŸ”Š ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª",
        "audio_preview": "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ØµÙˆØª",
        "audio_file": "Ù…Ù„Ù Ø§Ù„ØµÙˆØª",
        "subtitles": "Ø§Ù„ØªØ±Ø¬Ù…Ø© (.srt)",
        "zip_bundle": "ğŸ“¦ Ø­Ø²Ù…Ø© ZIP",
        "clean_title": "### ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ±Ø¯ÙŠ",
        "clean_desc": "Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø­Ø±ÙˆÙ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ÙƒØ±Ø¯ÙŠØ©.",
        "original_text": "Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ",
        "clean_btn": "ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ",
        "cleaned_text": "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø¸Ù",
        "usage_tips": "### Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
        "tip_q": "- **Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©**: Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… (ØŒ . ØŸ !)",
        "tip_l": "- **Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©**: Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù„ÙØ§Øª .txt Ù„Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
        "tip_s": "- **Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ Ø§Ù„Ø³ÙˆØ±Ø§Ù†ÙŠØ©**: ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ",
        "tip_v": "- **Ù„ØµÙ†Ø§Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ**: Ø­Ù…Ù„ Ø­Ø²Ù…Ø© ZIP (ØµÙˆØª + ØªØ±Ø¬Ù…Ø©)",
        "footer": "<strong>Ø¯Ù„ÙÙŠÙ† Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…</strong> â€¢ ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© <em>Ù‡ÙŠÙ„Ø¯Ù† Ù‡ÙŠØ³ØªÙŠØ§Ø± Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡</em>",
        "error_empty": "âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ!",
        "error_clean_empty": "âŒ Ø§Ù„Ù†Øµ Ø£ØµØ¨Ø­ ÙØ§Ø±ØºØ§Ù‹ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ!",
        "error_process": "âŒ ØªØ¹Ø°Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ!",
        "habibi_dialects_label": "Ù„Ù‡Ø¬Ø§Øª Ø¹Ø±Ø¨ÙŠØ© (Ø­Ø¨ÙŠØ¨ÙŠ)",
        "habibi_clone_label": "ğŸ™ï¸ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„ØµÙˆØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
        "habibi_ref_wav_label": "ØµÙˆØª Ù…Ø±Ø¬Ø¹ÙŠ",
        "habibi_ref_txt_label": "Ù†Øµ Ù…Ø±Ø¬Ø¹ÙŠ",
        "habibi_ref_txt_placeholder": "Ù…Ø§Ø°Ø§ ÙŠÙ‚Ø§Ù„ ÙÙŠ Ø§Ù„ØµÙˆØªØŸ",
        "kokoro_lang_label": "Ø§Ù„Ù„ØºØ©",
        "kokoro_voice_label": "Ø§Ù„ØµÙˆØª"
    }
}

model_cache = {}

# --- TEXT CLEANER ---
def normalize_kurdish_text(text: str) -> str:
    if not text: return ""
    text = text.replace('4', 'Ù¤').replace('5', 'Ù¥').replace('6', 'Ù¦')
    text = text.replace('Û´', 'Ù¤').replace('Ûµ', 'Ù¥').replace('Û¶', 'Ù¦')
    eng_to_ku = str.maketrans("0123456789", "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©")
    text = text.translate(eng_to_ku)
    replacements = {
        'Ùƒ': 'Ú©', 'ÙŠ': 'ÛŒ', 'Ù‰': 'ÛŒ', 'Ø©': 'Û•',
        'Ú‡': 'Ú†', 'Ú¤': 'Ú¤', 'Ú¥': 'Ú¤', 'Ú¦': 'Ù¾',
        'Ù‡â€Œ': 'Û•', 'Û•â€Œ': 'Û•', 'Û†': 'Û†', 'Û': 'Û',
        'Ú•': 'Ú•', 'Úµ': 'Úµ', '?': 'ØŸ', ',': 'ØŒ', ';': 'Ø›'
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text

def auto_punctuate(text):
    if not text.strip(): return text
    text = re.sub(r'([.ØŸ!?ØŒ])(\S)', r'\1 \2', text)
    if not re.search(r'[.ØŸ!]\s*$', text.strip()):
        text = text.rstrip() + '.'
    return text

def split_into_chunks(text, max_chars=400):
    text = re.sub(r'\s+', ' ', text.strip())
    if len(text) <= max_chars: return [text]
    parts = re.split(r'([.ØŸ!]+)', text)
    sentences = []
    for i in range(0, len(parts)-1, 2):
        s = parts[i] + parts[i+1]
        if s.strip(): sentences.append(s.strip())
    if len(parts)%2==1 and parts[-1].strip(): sentences.append(parts[-1].strip())
    chunks, current = [], ""
    for s in sentences:
        if current and len(current) + len(s) + 1 > max_chars:
            chunks.append(current)
            current = s
        else: current = current + " " + s if current else s
    if current: chunks.append(current)
    return chunks

# --- AUDIO ENGINE ---
def load_habibi_model(dialect="MSA"):
    try:
        from f5_tts.infer.utils_infer import load_model as f5_load_model
        from f5_tts.model import DiT
        from cached_path import cached_path
        
        cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)
        
        # We'll use the Unified model by default as it's the most flexible
        ckpt_url = "hf://SWivid/Habibi-TTS/Unified/model_200000.safetensors"
        vocab_url = "hf://SWivid/Habibi-TTS/Unified/vocab.txt"
        
        ckpt_path = str(cached_path(ckpt_url))
        vocab_path = str(cached_path(vocab_url))
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = f5_load_model(DiT, cfg, ckpt_path, vocab_file=vocab_path, device=device)
        return model, "habibi"
    except Exception as e:
        logger.error(f"Habibi load failed: {e}")
        return None, str(e)

def load_kokoro_model(lang_code='a'):
    key = f"kokoro_{lang_code}"
    if key in model_cache: return model_cache[key]
    try:
        from kokoro import KPipeline
        logger.info(f"ğŸš€ Loading Kokoro model for {lang_code}...")
        pipeline = KPipeline(lang_code=lang_code)
        model_cache[key] = (pipeline, "kokoro")
        return pipeline, "kokoro"
    except Exception as e:
        logger.error(f"Kokoro load failed: {e}")
        return None, str(e)

def load_voice_model(dialect_name, kokoro_lang_code='a'):
    if dialect_name == "Arabic (Habibi - Dialectal)":
        return load_habibi_model()
    if dialect_name == "Multi-Language (Kokoro-82M)":
        return load_kokoro_model(kokoro_lang_code)
        
    if dialect_name in model_cache: return model_cache[dialect_name]
    try:
        logger.info(f"ğŸš€ Loading model for {dialect_name}...")
        try:
            # First attempt: Try loading from local cache ONLY (true offline)
            model = VitsModel.from_pretrained(MODELS[dialect_name], cache_dir=MODEL_CACHE_DIR, local_files_only=True)
            tokenizer = AutoTokenizer.from_pretrained(MODELS[dialect_name], cache_dir=MODEL_CACHE_DIR, local_files_only=True)
        except Exception as offline_err:
            # Second attempt: If not in cache, download it
            logger.info(f"ğŸ“¡ Model not found in local cache or checking for updates... ({dialect_name})")
            model = VitsModel.from_pretrained(MODELS[dialect_name], cache_dir=MODEL_CACHE_DIR, local_files_only=False)
            tokenizer = AutoTokenizer.from_pretrained(MODELS[dialect_name], cache_dir=MODEL_CACHE_DIR, local_files_only=False)
            
        model_cache[dialect_name] = (model, tokenizer)
        return model, tokenizer
    except Exception as e:
        error_msg = str(e)
        if "incomplete metadata" in error_msg or "deserializing" in error_msg:
            error_msg = "âŒ Corrupted model file detected! Please delete the 'models_cache' folder and restart the app to redownload."
        logger.error(f"Failed: {error_msg}")
        return None, error_msg

def format_timestamp(s):
    ms = int((s % 1) * 1000)
    s = int(s)
    return f"{s//3600:02}:{(s%3600)//60:02}:{s%60:02},{ms:03}"

def generate_audio_engine(text, dialect, speed, pitch, use_mp3, p_s, p_l, habibi_dialect="MSA", habibi_ref_wav=None, habibi_ref_txt="", kokoro_lang="a", kokoro_voice="af_bella"):
    if not text.strip(): raise gr.Error("Empty!")
    text = normalize_kurdish_text(text)
    if not re.search(r'[.ØŸ!,ØŒ]', text[:50]): text = auto_punctuate(text)
    
    m_obj = load_voice_model(dialect, kokoro_lang)
    if not m_obj[0]: raise gr.Error(str(m_obj[1]))
    
    if m_obj[1] == "habibi":
        try:
            from habibi_tts.infer.utils_infer import infer_process
            from f5_tts.infer.utils_infer import load_vocoder, preprocess_ref_audio_text
            from habibi_tts.model.utils import dialect_id_map
            
            model = m_obj[0]
            vocoder = load_vocoder()
            
            # Prepare reference audio
            if not habibi_ref_wav:
                # Use bundled asset as fallback
                from importlib.resources import files
                habibi_ref_wav = str(files("habibi_tts").joinpath(f"assets/{habibi_dialect if habibi_dialect != 'OMN' else 'MSA'}.mp3"))
                if habibi_dialect == "MSA" or not habibi_ref_txt:
                    habibi_ref_txt = "ÙƒØ§Ù† Ø§Ù„Ù„Ø¹ÙŠØ¨ Ø­Ø§Ø¶Ø±Ù‹Ø§ ÙÙŠ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ù†Ø´Ø·Ø© ÙˆØ§Ù„ÙØ¹Ø§Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù…."
            
            ref_audio, ref_text = preprocess_ref_audio_text(habibi_ref_wav, habibi_ref_txt)
            dialect_id = dialect_id_map.get(habibi_dialect[:3], None)
            
            final_wave, sr, _ = infer_process(
                ref_audio, ref_text, text, model, vocoder,
                speed=speed, dialect_id=dialect_id
            )
            f_aud = final_wave
        except Exception as e:
            raise gr.Error(f"Habibi Inference Error: {e}")
    elif m_obj[1] == "kokoro":
        try:
            pipeline = m_obj[0]
            generator = pipeline(text, voice=kokoro_voice, speed=speed, split_pattern=r'\n+')
            audio_list = []
            for gs, ps, audio in generator:
                audio_list.append(audio)
            if not audio_list: raise gr.Error("Kokoro failed to generate audio.")
            f_aud = np.concatenate(audio_list)
            sr = 24000
            srt_content = f"1\n00:00:00,000 --> {format_timestamp(len(f_aud)/sr)}\n{text}\n"
        except Exception as e:
            raise gr.Error(f"Kokoro Inference Error: {e}")
    else:
        model, tok = m_obj
        sr = model.config.sampling_rate
        chunks = split_into_chunks(text.strip())
        
        aud_segs, srt_segs, cur_t = [], [], 0.0
        for i, ch in enumerate(chunks):
            parts = re.split(r'([.ØŸ!:\n]+|\[p\]|\[s\])', ch)
            ch_aud, ch_t = [], 0.0
            for p in parts:
                p = p.strip()
                if not p: continue
                if p == "[p]": 
                    ch_aud.append(np.zeros(int(sr*p_l))); ch_t+=p_l; continue
                if p == "[s]" or re.match(r'^[.ØŸ!:\n]+$', p):
                    ch_aud.append(np.zeros(int(sr*p_s))); ch_t+=p_s; continue
                if len(p) < 2: continue
                ins = tok(p, return_tensors="pt")
                if ins['input_ids'].shape[-1] == 0: continue
                with torch.no_grad(): out = model(**ins).waveform
                seg = out.float().numpy().T.flatten()
                if speed != 1.0: seg = librosa.effects.time_stretch(seg, rate=speed)
                if pitch != 0: seg = librosa.effects.pitch_shift(seg, sr=sr, n_steps=pitch)
                dur = len(seg)/sr
                srt_segs.append(f"{len(srt_segs)+1}\n{format_timestamp(cur_t+ch_t)} --> {format_timestamp(cur_t+ch_t+dur)}\n{p}\n\n")
                ch_aud.append(seg); ch_aud.append(np.zeros(int(sr*0.1))); ch_t += dur+0.1
            if ch_aud:
                aud_segs.append(np.concatenate(ch_aud))
                cur_t += ch_t
                if i < len(chunks)-1:
                    aud_segs.append(np.zeros(int(sr*p_l))); cur_t += p_l
        
        if not aud_segs: return None, None, None, None
        f_aud = np.concatenate(aud_segs)
        srt_content = "".join(srt_segs)

    # Common normalization and output
    f_aud = np.nan_to_num(f_aud)
    mv = np.max(np.abs(f_aud))
    if mv > 1e-6: f_aud = (f_aud / mv * 32767).astype(np.int16)
    else: f_aud = f_aud.astype(np.int16)
    
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    w_p = os.path.join(OUTPUT_FOLDER, f"audio_{ts}.wav")
    sf.write(w_p, f_aud, sr)
    f_p = w_p
    if use_mp3:
        m_p = w_p.replace(".wav", ".mp3")
        try:
            AudioSegment.from_wav(w_p).export(m_p, format="mp3", bitrate="192k")
            f_p = m_p
        except: pass
    
    s_p = w_p.replace(".wav", ".srt")
    if m_obj[1] == "habibi": # For Habibi, we don't have per-chunk timestamps yet in this simple impl
        with open(s_p, "w", encoding="utf-8") as f: f.write(f"1\n00:00:00,000 --> {format_timestamp(len(f_aud)/sr)}\n{text}\n")
    else:
        with open(s_p, "w", encoding="utf-8") as f: f.write(srt_content)
        
    z_p = w_p.replace(".wav", ".zip")
    with zipfile.ZipFile(z_p, 'w') as z:
        z.write(f_p, os.path.basename(f_p))
        z.write(s_p, os.path.basename(s_p))
    return (sr, f_aud), f_p, s_p, z_p

# --- UI LOGIC ---
# Fixed typo in ui_lang (d vs t)
def ui_lang_fixed(l):
    d = TRANSLATIONS[l]
    return [
        gr.update(value="# "+d["title"]), 
        gr.update(label=d["dialect"]),
        gr.update(label=d["upload_txt"]),
        gr.update(value=d["unlimited_text"]),
        gr.update(label=d["input_label"], placeholder=d["input_placeholder"]),
        gr.update(label=d["pauses_accordion"]),
        gr.update(label=d["comma_pause"]),
        gr.update(label=d["sentence_pause"]),
        gr.update(label=d["audio_settings"]),
        gr.update(label=d["speed"]),
        gr.update(label=d["pitch"]),
        gr.update(label=d["export_mp3"]),
        gr.update(value=d["generate_btn"]),
        gr.update(label=d["audio_preview"]),
        gr.update(label=d["audio_file"]),
        gr.update(label=d["subtitles"]),
        gr.update(label=d["zip_bundle"]),
        gr.update(value=d["clean_title"]),
        gr.update(value=d["clean_desc"]),
        gr.update(label=d["original_text"]),
        gr.update(value=d["clean_btn"]),
        gr.update(label=d["cleaned_text"]),
        gr.update(value=d["usage_tips"]),
        gr.update(value=d["tip_q"]),
        gr.update(value=d["tip_l"]),
        gr.update(value=d["tip_s"]),
        gr.update(value=d["tip_v"]),
        gr.update(value=d["footer"]),
        gr.update(label=d["studio_tab"]),
        gr.update(label=d["cleaner_tab"]),
        gr.update(label=d["about_tab"]),
        gr.update(label=d["habibi_dialects_label"]),
        gr.update(label=d["habibi_clone_label"]),
        gr.update(label=d["habibi_ref_wav_label"]),
        gr.update(label=d["habibi_ref_txt_label"], placeholder=d["habibi_ref_txt_placeholder"]),
        gr.update(label=d["kokoro_lang_label"]),
        gr.update(label=d["kokoro_voice_label"])
    ]

theme = gr.themes.Soft(primary_hue="teal", neutral_hue="slate")
with gr.Blocks(title="Dolphin KURDISH TTS") as demo:
    with gr.Row():
        tit = gr.Markdown("# ğŸ¬ Dolphin KURDISH TTS")
        ls = gr.Radio(["Kurdish", "English", "Arabic"], value="English", label="Language / Ø²Ù…Ø§Ù† / Ø§Ù„Ù„ØºØ©")
    
    with gr.Tabs() as ts:
        with gr.TabItem("ğŸ›ï¸ Studio", id=0) as t1:
            with gr.Row():
                with gr.Column():
                    dia = gr.Dropdown(list(MODELS.keys()), value="Sorani", label="Dialect")
                    
                    # Arabic Dialect Options
                    with gr.Column(visible=False) as arb_dialect_params:
                        h_dia = gr.Dropdown(HABIBI_DIALECTS, value="MSA", label="Arabic Dialects (Habibi)")
                        with gr.Accordion("ğŸ™ï¸ Voice Cloning (Optional for Habibi)", open=False) as a3:
                            h_wav = gr.Audio(label="Reference Audio", type="filepath")
                            h_txt = gr.Textbox(label="Reference Text", placeholder="What is said in the audio?", rtl=True)
                            
                    # Kokoro Options
                    with gr.Column(visible=False) as kokoro_params:
                        k_lang = gr.Dropdown(list(KOKORO_LANGS.keys()), value="American English", label="Language")
                        k_voice = gr.Dropdown(KOKORO_VOICES["a"], value="af_bella", label="Voice")
                            
                    upl = gr.File(label="ğŸ“„ Upload .txt file", file_types=[".txt"], type="filepath")
                    lm = gr.Markdown("âœ… Supports unlimited text length!")
                    txt = gr.Textbox(lines=10, label="Input Kurdish Text", rtl=True, placeholder="Enter text...")
                    with gr.Accordion("â¸ï¸ Natural Pauses", open=False) as a1:
                        ps = gr.Slider(0.2, 0.8, value=0.4, label="Comma pause")
                        pl = gr.Slider(0.8, 2.0, value=1.3, label="Sentence pause")
                    with gr.Accordion("âš™ï¸ Audio Settings", open=True) as a2:
                        sp = gr.Slider(0.5, 2.0, value=1.0, label="Speed")
                        pt = gr.Slider(-5, 5, value=0, step=1, label="Pitch")
                        mp3 = gr.Checkbox(label="Export as MP3", value=False)
                    btn = gr.Button("ğŸ”Š Generate Speech", variant="primary")
                with gr.Column():
                    a_p = gr.Audio(label="Audio Preview")
                    a_f = gr.File(label="Audio File")
                    s_f = gr.File(label="Subtitles (.srt)")
                    z_f = gr.File(label="ğŸ“¦ ZIP Bundle")
        
        with gr.TabItem("ğŸ§¹ Text Cleaner", id=1) as t2:
            c1 = gr.Markdown("### Fix broken Kurdish characters"); c2 = gr.Markdown("Paste messy text...")
            raw = gr.Textbox(lines=6, label="Original Text", rtl=True)
            cbtn = gr.Button("Clean Text", variant="secondary")
            cout = gr.Textbox(lines=6, label="Cleaned Text", rtl=True)
            
        with gr.TabItem("â„¹ï¸ About", id=2) as t3:
            gr.Markdown("# ğŸ¬ Dolphin KURDISH TTS\nCreated by: Heldn Hastyar Abdullah")

    ut = gr.Markdown("### Usage Tips")
    m1 = gr.Markdown("- **Max quality**: Use punctuation"); m2 = gr.Markdown("- **Long texts**: Use .txt files")
    m3 = gr.Markdown("- **Sorani**: Auto-fix enabled"); m4 = gr.Markdown("- **Video**: Download ZIP")
    ft = gr.HTML("<div style='text-align: center; padding: 15px;'><strong>ğŸ¬ Dolphin KURDISH TTS</strong></div>")

    # Dynamic visibility logic
    def update_visibility(d):
        return [
            gr.update(visible=(d == "Arabic (Habibi - Dialectal)")),
            gr.update(visible=(d == "Multi-Language (Kokoro-82M)"))
        ]

    def update_kokoro_voices(lang_name):
        lang_code = KOKORO_LANGS[lang_name]
        voices = KOKORO_VOICES[lang_code]
        return gr.update(choices=voices, value=voices[0])

    dia.change(update_visibility, [dia], [arb_dialect_params, kokoro_params])
    k_lang.change(update_kokoro_voices, [k_lang], [k_voice])

    ls.change(ui_lang_fixed, [ls], [tit, dia, upl, lm, txt, a1, ps, pl, a2, sp, pt, mp3, btn, a_p, a_f, s_f, z_f, c1, c2, raw, cbtn, cout, ut, m1, m2, m3, m4, ft, t1, t2, t3, h_dia, a3, h_wav, h_txt, k_lang, k_voice])
    upl.change(lambda f: open(f.name, encoding='utf-8', errors='ignore').read() if f else "", [upl], [txt])
    btn.click(generate_audio_engine, [txt, dia, sp, pt, mp3, ps, pl, h_dia, h_wav, h_txt, k_lang, k_voice], [a_p, a_f, s_f, z_f])
    cbtn.click(normalize_kurdish_text, [raw], [cout])

if __name__ == "__main__":
    print("Status: Ready! Launching browser...")
    try:
        import pyi_splash
        pyi_splash.close()
    except:
        pass
    demo.launch(inbrowser=True, theme=theme)